# ğŸ‰ Submission & Leaderboard Setup Complete!

Your repository is now configured for fully automated scoring with a CSVâ€‘based leaderboard and an interactive GitHub Pages view.

## âœ… Whatâ€™s in Place

### Leaderboard System
- **`leaderboard/leaderboard.csv`** â€” Source of truth
- **`leaderboard.md`** â€” Auto-generated static view
- **`docs/leaderboard.html`** â€” Interactive leaderboard (GitHub Pages)

### Automation
- **`.github/workflows/score-submission.yml`** â€” CI scoring and leaderboard updates
- **`competition/validate_submission.py`** â€” Validates submission format
- **`update_leaderboard.py`** â€” Scores and updates CSV/Markdown/Docs

### Submission Format
Submissions must be:
```
submissions/inbox/<team>/<run_id>/predictions.csv
submissions/inbox/<team>/<run_id>/metadata.json
```
`predictions.csv` columns:
- `id`
- `y_pred` (probability or hard label)

## ğŸš€ How It Works (Automated)
1. Participant opens PR with `predictions.csv` + `metadata.json`.
2. CI validates, scores, and comments on the PR.
3. On merge, CI appends results to `leaderboard/leaderboard.csv`.
4. `leaderboard.md` and `docs/leaderboard.csv` are regenerated.

## âœ… Final Steps for You
1. **Enable GitHub Actions** (Settings â†’ Actions â†’ General)
2. **Enable GitHub Pages** (Settings â†’ Pages â†’ main /docs)
3. **Add test labels as a secret** for CI scoring

## ğŸ“ Leaderboard URL
Once Pages is enabled:
```
https://<org>.github.io/<repo>/leaderboard.html
```
